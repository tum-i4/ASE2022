{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd3a3383",
   "metadata": {
    "papermill": {
     "duration": 0.022048,
     "end_time": "2022-05-06T12:24:26.482233",
     "exception": false,
     "start_time": "2022-05-06T12:24:26.460185",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Security Classification via LDA Topic Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c9867b",
   "metadata": {
    "papermill": {
     "duration": 0.018376,
     "end_time": "2022-05-06T12:24:26.519824",
     "exception": false,
     "start_time": "2022-05-06T12:24:26.501448",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. Acknowledgements\n",
    "2. Import libraries\n",
    "3. Load Data\n",
    "4. Prepare Data\n",
    "5. Generating security stop words\n",
    "6. Coherence evaluation\n",
    "6. Latent Dirichlet Allocation - Topic model generation\n",
    "7. Classification\n",
    "8. Evaluation\n",
    "9. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d9840d",
   "metadata": {
    "papermill": {
     "duration": 0.018344,
     "end_time": "2022-05-06T12:24:26.557169",
     "exception": false,
     "start_time": "2022-05-06T12:24:26.538825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Acknowledgements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4957376",
   "metadata": {
    "papermill": {
     "duration": 0.018795,
     "end_time": "2022-05-06T12:24:26.594685",
     "exception": false,
     "start_time": "2022-05-06T12:24:26.575890",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Create topic clusters from security settings with latent dirichlet allocation\n",
    "\n",
    "Reference: \n",
    "* https://towardsdatascience.com/topic-modelling-in-python-with-nltk-and-gensim-4ef03213cd21\n",
    "* https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24#:~:text=Latent%20Dirichlet%20Allocation%20(LDA)%20is,and%20split%20them%20into%20topics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9829769b",
   "metadata": {
    "papermill": {
     "duration": 0.019877,
     "end_time": "2022-05-06T12:24:26.633396",
     "exception": false,
     "start_time": "2022-05-06T12:24:26.613519",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f581dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T12:24:26.673758Z",
     "iopub.status.busy": "2022-05-06T12:24:26.673118Z",
     "iopub.status.idle": "2022-05-06T12:24:29.027012Z",
     "shell.execute_reply": "2022-05-06T12:24:29.025652Z"
    },
    "papermill": {
     "duration": 2.377229,
     "end_time": "2022-05-06T12:24:29.029859",
     "exception": false,
     "start_time": "2022-05-06T12:24:26.652630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from json import load\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.corpora import Dictionary\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from nltk import Text, word_tokenize, FreqDist\n",
    "from random import shuffle\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "import pyLDAvis.gensim\n",
    "import pickle\n",
    "from gensim import models\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "\n",
    "stop_w = gensim.parsing.preprocessing.STOPWORDS\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577096a7",
   "metadata": {
    "papermill": {
     "duration": 0.019758,
     "end_time": "2022-05-06T12:24:29.069424",
     "exception": false,
     "start_time": "2022-05-06T12:24:29.049666",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd0d21a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T12:24:29.111419Z",
     "iopub.status.busy": "2022-05-06T12:24:29.110381Z",
     "iopub.status.idle": "2022-05-06T12:24:29.118236Z",
     "shell.execute_reply": "2022-05-06T12:24:29.117537Z"
    },
    "papermill": {
     "duration": 0.031231,
     "end_time": "2022-05-06T12:24:29.120565",
     "exception": false,
     "start_time": "2022-05-06T12:24:29.089334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_prepare_data(path, name):\n",
    "    \"\"\"\n",
    "    1. Load labeled configuration settings from ase2022 dataset\n",
    "    2. Remove Internet Explorer settings\n",
    "    3. Prepare dataframe for binary classification\n",
    "    \n",
    "    Args:\n",
    "    path: path to data\n",
    "    name: name of system variant\n",
    "    \n",
    "    Returns: \n",
    "    A dataframe of the system variant\n",
    "    \n",
    "    \"\"\"\n",
    "    with open(path) as f_read:\n",
    "        docs_all = load(f_read)\n",
    "    shuffle(docs_all)\n",
    "    df = DataFrame([doc for doc in docs_all if doc[\"text\"].lower().find(\"windows components. internet explorer.\")==-1])\n",
    "    df['sec']=df['is_security_relevant'].apply(lambda x: 1 if x==True else 0)\n",
    "    df = df.drop('is_security_relevant', 1)\n",
    "    print(f\"{name} settings: {len(df)}\")\n",
    "    return df.text.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97fbfbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T12:24:29.163582Z",
     "iopub.status.busy": "2022-05-06T12:24:29.162921Z",
     "iopub.status.idle": "2022-05-06T12:24:29.712141Z",
     "shell.execute_reply": "2022-05-06T12:24:29.710636Z"
    },
    "papermill": {
     "duration": 0.572308,
     "end_time": "2022-05-06T12:24:29.714498",
     "exception": false,
     "start_time": "2022-05-06T12:24:29.142190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs: dict = {\"CIS_18_sec\": load_prepare_data(\"../input/ase2022/docs/cis/1803/sec_docs.json\",\"SEC CIS 1803\"),\n",
    "              \"CIS_18_non_sec\": load_prepare_data(\"../input/ase2022/docs/cis/1803/non_sec_docs.json\",\"NON-SEC CIS 1803\"),\n",
    "              \"CIS_19_sec\": load_prepare_data(\"../input/ase2022/docs/cis/1909/sec_docs.json\", \"SEC CIS 1909\"), \n",
    "              \"CIS_19_non_sec\": load_prepare_data(\"../input/ase2022/docs/cis/1909/non_sec_docs.json\", \"NON-SEC CIS 1909\"), \n",
    "              \"CIS_Server_sec\": load_prepare_data(\"../input/ase2022/docs/cis/server2016/sec_docs.json\", \"SEC CIS Server2016\" ), \n",
    "              \"CIS_Server_non_sec\": load_prepare_data(\"../input/ase2022/docs/cis/server2016/non_sec_docs.json\", \"NON-SEC CIS Server2016\" ), \n",
    "              \"SIE_19_sec\": load_prepare_data(\"../input/ase2022/docs/siemens/1909/sec_docs.json\", \"SEC Siemens 1909\"), \n",
    "              \"SIE_19_non_sec\": load_prepare_data(\"../input/ase2022/docs/siemens/1909/non_sec_docs.json\", \"NON-SEC Siemens 1909\"), \n",
    "              \"SIE_Server_sec\": load_prepare_data(\"../input/ase2022/docs/siemens/server2016/sec_docs.json\",\"SEC Siemens Server2016\"),\n",
    "              \"SIE_Server_non_sec\": load_prepare_data(\"../input/ase2022/docs/siemens/server2016/non_sec_docs.json\",\"NON-SEC Siemens Server2016\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c5f753",
   "metadata": {
    "papermill": {
     "duration": 0.020811,
     "end_time": "2022-05-06T12:24:29.755965",
     "exception": false,
     "start_time": "2022-05-06T12:24:29.735154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fceb74b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T12:24:29.799637Z",
     "iopub.status.busy": "2022-05-06T12:24:29.799238Z",
     "iopub.status.idle": "2022-05-06T12:24:29.804586Z",
     "shell.execute_reply": "2022-05-06T12:24:29.803522Z"
    },
    "papermill": {
     "duration": 0.029905,
     "end_time": "2022-05-06T12:24:29.806543",
     "exception": false,
     "start_time": "2022-05-06T12:24:29.776638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    \"\"\"\n",
    "    1. apply WordNetLemmatizer on text input\n",
    "    2. apply SnowballStemmer\n",
    "    \"\"\"\n",
    "    return SnowballStemmer(\"english\").stem(WordNetLemmatizer().lemmatize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f709c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T12:24:29.849546Z",
     "iopub.status.busy": "2022-05-06T12:24:29.849150Z",
     "iopub.status.idle": "2022-05-06T12:24:29.855306Z",
     "shell.execute_reply": "2022-05-06T12:24:29.854320Z"
    },
    "papermill": {
     "duration": 0.030431,
     "end_time": "2022-05-06T12:24:29.857471",
     "exception": false,
     "start_time": "2022-05-06T12:24:29.827040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \"\"\"\n",
    "    1. apply simple_preprocess\n",
    "    2. remove stop words\n",
    "    3. keep words w of length 2 < w < 16\n",
    "    4. apply stemmer/lemmatizer\n",
    "    \"\"\"\n",
    "    result = [lemmatize_stemming(token) for token in gensim.utils.simple_preprocess(text) if (token not in gensim.parsing.preprocessing.STOPWORDS) and (len(token) > 2) and (len(token)<16)]\n",
    "    return [token for token in result if (token not in security_stop_words)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f23f8b",
   "metadata": {
    "papermill": {
     "duration": 0.019857,
     "end_time": "2022-05-06T12:24:29.898182",
     "exception": false,
     "start_time": "2022-05-06T12:24:29.878325",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Generating security stop words:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869fe144",
   "metadata": {
    "papermill": {
     "duration": 0.019634,
     "end_time": "2022-05-06T12:24:29.938836",
     "exception": false,
     "start_time": "2022-05-06T12:24:29.919202",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Most common words in security vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1941b9a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T12:24:29.982635Z",
     "iopub.status.busy": "2022-05-06T12:24:29.982204Z",
     "iopub.status.idle": "2022-05-06T12:24:32.717471Z",
     "shell.execute_reply": "2022-05-06T12:24:32.716111Z"
    },
    "papermill": {
     "duration": 2.759775,
     "end_time": "2022-05-06T12:24:32.720019",
     "exception": false,
     "start_time": "2022-05-06T12:24:29.960244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sec_lemma_tokens= Text(lemmatize_stemming(token) for document in docs['CIS_19_sec'] for token in word_tokenize(document.lower()) if token.isalpha() and (token not in gensim.parsing.preprocessing.STOPWORDS))\n",
    "f_dist_sec_lemma_tokens = FreqDist(sec_lemma_tokens)\n",
    "most_common = f_dist_sec_lemma_tokens.most_common(300)\n",
    "most_common_words = [w for (w,c) in most_common]\n",
    "print(most_common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335b410c",
   "metadata": {
    "papermill": {
     "duration": 0.020566,
     "end_time": "2022-05-06T12:24:32.762524",
     "exception": false,
     "start_time": "2022-05-06T12:24:32.741958",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Manual extraction of security stop words: frequent, but not security identifying words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5408f10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T12:24:32.808221Z",
     "iopub.status.busy": "2022-05-06T12:24:32.807164Z",
     "iopub.status.idle": "2022-05-06T12:24:32.816451Z",
     "shell.execute_reply": "2022-05-06T12:24:32.815719Z"
    },
    "papermill": {
     "duration": 0.034317,
     "end_time": "2022-05-06T12:24:32.818863",
     "exception": false,
     "start_time": "2022-05-06T12:24:32.784546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "security_stop_words={'abl', 'accept', 'activ', 'add', 'addit', 'affect', 'algorithm', 'allow', 'alreadi', 'also', 'alway', 'appear', 'avail', 'back', 'bar', 'behavior', 'box', 'charact', 'check', 'choos', 'client', 'client', 'com', 'command', 'comput', 'comput', 'configur', 'configur', 'control', 'creat', 'decid', 'default', 'desktop', 'determin', 'disabl', 'domain', 'edg', 'effect', 'employe', 'enabl', 'exampl', 'field', 'fix', 'follow', 'host', 'howev', 'includ', 'input', 'instead', 'kilobyt', 'let', 'local', 'longer', 'make', 'manag', 'may', 'megabyt', 'method', 'method', 'microsoft', 'ms', 'must', 'new', 'offer', 'one', 'oper', 'option', 'option', 'order', 'polici', 'polici', 'powershel', 'prevent', 'process', 'prompt', 'properti', 'public', 'rdp', 'reach', 'remov', 'requir', 'resum', 'select', 'set', 'set', 'specifi', 'state', 'still', 'system', 'take', 'task', 'temporari', 'terabyt', 'tool', 'tpm', 'turn', 'type', 'usb', 'use', 'user', 'user', 'valu', 'via', 'vista', 'want', 'whether', 'window', 'winrm', 'without', 'folder', 'devic', 'server', 'remot', 'password', 'data', 'featur'}\n",
    "print(security_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab362b41",
   "metadata": {
    "papermill": {
     "duration": 0.020925,
     "end_time": "2022-05-06T12:24:32.861708",
     "exception": false,
     "start_time": "2022-05-06T12:24:32.840783",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Coherence evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50535483",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T12:24:32.906313Z",
     "iopub.status.busy": "2022-05-06T12:24:32.905701Z",
     "iopub.status.idle": "2022-05-06T12:24:32.912176Z",
     "shell.execute_reply": "2022-05-06T12:24:32.911336Z"
    },
    "papermill": {
     "duration": 0.032048,
     "end_time": "2022-05-06T12:24:32.914734",
     "exception": false,
     "start_time": "2022-05-06T12:24:32.882686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.tutorialspoint.com/gensim/gensim_documents_and_lda_model.htm\n",
    "# https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0#:~:text=Topic%20Coherence%20measures%20score%20a,are%20artifacts%20of%20statistical%20inference.\n",
    "def coherence_values_computation(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    build coherence models for different numbers of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=4, alpha='auto', per_word_topics=True)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = gensim.models.coherencemodel.CoherenceModel(model=model, texts=texts, dictionary=dictionary)\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793cf194",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T12:24:32.961224Z",
     "iopub.status.busy": "2022-05-06T12:24:32.960614Z",
     "iopub.status.idle": "2022-05-06T12:24:46.439422Z",
     "shell.execute_reply": "2022-05-06T12:24:46.437864Z"
    },
    "papermill": {
     "duration": 13.505189,
     "end_time": "2022-05-06T12:24:46.442064",
     "exception": false,
     "start_time": "2022-05-06T12:24:32.936875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def coherence_evaluation(docs_input): \n",
    "    \"\"\"\n",
    "    evaluate and plot coherence values\n",
    "    \"\"\"\n",
    "    text_data = [preprocess(doc.lower()) for doc in docs_input]\n",
    "    dictionary = gensim.corpora.Dictionary.load('../input/ase2022/dictionary.gensim')\n",
    "    corpus = pickle.load(open('../input/ase2022/corpus.pkl', 'rb'))\n",
    "    tfidf = models.TfidfModel(corpus)\n",
    "    corpus_tfidf = tfidf[corpus]\n",
    "    model_list, coherence_values = coherence_values_computation (dictionary=dictionary, corpus=corpus_tfidf, texts=text_data, start=1, limit=30)\n",
    "    x = range(1, 30, 3)\n",
    "    plt.plot(x, coherence_values)\n",
    "    plt.xlabel(\"Num Topics\")\n",
    "    plt.ylabel(\"Coherence score\")\n",
    "    plt.legend(\"coherence_values\", loc='best')\n",
    "    plt.savefig('CoherenceEval.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    for m, cv in zip(x, coherence_values):\n",
    "        print(\"Num Topics =\", m, \" is having Coherence Value of\", round(cv, 4))\n",
    "    return model_list\n",
    "coherence_evaluation(docs['CIS_19_sec'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf5d4ef",
   "metadata": {
    "papermill": {
     "duration": 0.021937,
     "end_time": "2022-05-06T12:24:46.486834",
     "exception": false,
     "start_time": "2022-05-06T12:24:46.464897",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Latent Dirichlet Allocation - Topic model generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe3214",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T12:24:46.536833Z",
     "iopub.status.busy": "2022-05-06T12:24:46.536438Z",
     "iopub.status.idle": "2022-05-06T12:24:46.544957Z",
     "shell.execute_reply": "2022-05-06T12:24:46.543812Z"
    },
    "papermill": {
     "duration": 0.035494,
     "end_time": "2022-05-06T12:24:46.547324",
     "exception": false,
     "start_time": "2022-05-06T12:24:46.511830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lda_topic_model_generation(docs_input):\n",
    "    \"\"\"\n",
    "    build lda topic model with 9 topics using TF-IDF model\n",
    "    \"\"\"\n",
    "    text_data = [preprocess(doc.lower()) for doc in docs_input]\n",
    "    dictionary = corpora.Dictionary(text_data)\n",
    "    corpus = [dictionary.doc2bow(text) for text in text_data]\n",
    "    pickle.dump(corpus, open('corpusNew.pkl', 'wb'))\n",
    "    dictionary.save('dictionaryNew.gensim')\n",
    "    tfidf = models.TfidfModel(corpus)\n",
    "    corpus_tfidf = tfidf[corpus]\n",
    "    n_topics = 9\n",
    "    ldamodel = gensim.models.LdaModel(corpus_tfidf, num_topics=n_topics, id2word=dictionary,passes=4, alpha='auto')\n",
    "    topics = ldamodel.print_topics(num_words=10)\n",
    "    for topic in topics:\n",
    "        print(topic)\n",
    "    ldamodel.save(f\"modelNew.gensim\")  \n",
    "\n",
    "    return ldamodel\n",
    "\n",
    "# Uncomment to train a new topic model\n",
    "# model = lda_topic_model_generation(docs['CIS_19_sec'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b38a36",
   "metadata": {
    "papermill": {
     "duration": 0.022915,
     "end_time": "2022-05-06T12:24:46.594094",
     "exception": false,
     "start_time": "2022-05-06T12:24:46.571179",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f7cffb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T12:24:46.644755Z",
     "iopub.status.busy": "2022-05-06T12:24:46.644418Z",
     "iopub.status.idle": "2022-05-06T12:24:46.652243Z",
     "shell.execute_reply": "2022-05-06T12:24:46.651100Z"
    },
    "papermill": {
     "duration": 0.036084,
     "end_time": "2022-05-06T12:24:46.654834",
     "exception": false,
     "start_time": "2022-05-06T12:24:46.618750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def classification(docs_input: [], model, threshold, trained_dict, tfidf): \n",
    "    \"\"\"\n",
    "    classify input documents: if topic probability for one of the topics is > threshold -> doc is sec-relevant\n",
    "    \"\"\"\n",
    "    sec_counter = []\n",
    "    for doc in docs_input:\n",
    "        sec_relevant = False\n",
    "        new_doc = preprocess(doc.lower())\n",
    "        new_doc_bow = trained_dict.doc2bow(new_doc)\n",
    "        doc_tfidf = tfidf[new_doc_bow]\n",
    "        res = model.get_document_topics(doc_tfidf)\n",
    "        for (t,r) in res:\n",
    "            if r>threshold:\n",
    "                sec_relevant = True\n",
    "        sec_counter.append(1) if sec_relevant else sec_counter.append(0)\n",
    "    return sec_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0ba699",
   "metadata": {
    "papermill": {
     "duration": 0.024314,
     "end_time": "2022-05-06T12:24:46.702153",
     "exception": false,
     "start_time": "2022-05-06T12:24:46.677839",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d2bb1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T12:24:46.751258Z",
     "iopub.status.busy": "2022-05-06T12:24:46.750924Z",
     "iopub.status.idle": "2022-05-06T12:24:46.760054Z",
     "shell.execute_reply": "2022-05-06T12:24:46.759335Z"
    },
    "papermill": {
     "duration": 0.03504,
     "end_time": "2022-05-06T12:24:46.761863",
     "exception": false,
     "start_time": "2022-05-06T12:24:46.726823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluation(sec_docs: [], non_sec_docs: [],model, threshold, trained_dict):\n",
    "    \"\"\"\n",
    "    evaluate the model on the input data\n",
    "    \"\"\"\n",
    "    all_docs = sec_docs+non_sec_docs\n",
    "    text_data = [preprocess(doc.lower()) for doc in all_docs]\n",
    "    corpus = [trained_dict.doc2bow(text) for text in text_data]\n",
    "    tfidf = models.TfidfModel(corpus)\n",
    "    \n",
    "    test_y = [1 for i in sec_docs]+[0 for i in non_sec_docs]\n",
    "    y_pred_sec = classification(sec_docs, model, threshold, trained_dict, tfidf)\n",
    "    y_pred_non_sec = classification(non_sec_docs, model, threshold, trained_dict, tfidf)\n",
    "    y_pred=y_pred_sec+y_pred_non_sec\n",
    "    \n",
    "    prec = precision_score(test_y, y_pred, zero_division=0)\n",
    "    rec = recall_score(test_y, y_pred, zero_division=0)\n",
    "    f1 = f1_score(test_y,y_pred, zero_division=0)\n",
    "    bal_acc = balanced_accuracy_score(test_y,y_pred)\n",
    "    \n",
    "    print('Precision: {:4.2f}'.format(prec))\n",
    "    print('Recall: {:4.2f}'.format(rec))\n",
    "    print('F-Score: {:4.2f}'.format(f1))\n",
    "    print('Balanced accuracy: {:4.2f}'.format(bal_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e388a5ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T12:24:46.810015Z",
     "iopub.status.busy": "2022-05-06T12:24:46.809677Z",
     "iopub.status.idle": "2022-05-06T12:24:46.815699Z",
     "shell.execute_reply": "2022-05-06T12:24:46.814648Z"
    },
    "papermill": {
     "duration": 0.03317,
     "end_time": "2022-05-06T12:24:46.817832",
     "exception": false,
     "start_time": "2022-05-06T12:24:46.784662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def classify_and_evaluate(eval_sec, eval_non_sec, name):\n",
    "    \"\"\"\n",
    "    classify input docs with threshold of 0.7 and evaluate\n",
    "    \"\"\"\n",
    "    dictionary = gensim.corpora.Dictionary.load('../input/ase2022/dictionary.gensim')\n",
    "    ldamodel = gensim.models.ldamodel.LdaModel.load('../input/ase2022/model.gensim')\n",
    "    t=0.7\n",
    "    print(f\"\\nThreshold {t}:\")\n",
    "    print(name)\n",
    "    evaluation(eval_sec, eval_non_sec, ldamodel, t, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5585f0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T12:24:46.865025Z",
     "iopub.status.busy": "2022-05-06T12:24:46.864364Z",
     "iopub.status.idle": "2022-05-06T12:25:41.358371Z",
     "shell.execute_reply": "2022-05-06T12:25:41.357312Z"
    },
    "papermill": {
     "duration": 54.520805,
     "end_time": "2022-05-06T12:25:41.361341",
     "exception": false,
     "start_time": "2022-05-06T12:24:46.840536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "classify_and_evaluate(docs['CIS_18_sec'], docs['CIS_18_non_sec'], \"CIS 1803: \")\n",
    "classify_and_evaluate(docs['CIS_19_sec'], docs['CIS_19_non_sec'], \"CIS 1909: \")\n",
    "classify_and_evaluate(docs['SIE_19_sec'], docs['SIE_19_non_sec'], \"Siemens 1909: \")\n",
    "classify_and_evaluate(docs['CIS_Server_sec'], docs['CIS_Server_non_sec'],\"CIS Server 2016: \")\n",
    "classify_and_evaluate(docs['SIE_Server_sec'], docs['SIE_Server_non_sec'],\"Siemens Server 2016: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d1e3be",
   "metadata": {
    "papermill": {
     "duration": 0.024278,
     "end_time": "2022-05-06T12:25:41.410912",
     "exception": false,
     "start_time": "2022-05-06T12:25:41.386634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Topic Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28194355",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T12:25:41.462543Z",
     "iopub.status.busy": "2022-05-06T12:25:41.461859Z",
     "iopub.status.idle": "2022-05-06T12:25:43.743962Z",
     "shell.execute_reply": "2022-05-06T12:25:43.742892Z"
    },
    "papermill": {
     "duration": 2.313383,
     "end_time": "2022-05-06T12:25:43.749333",
     "exception": false,
     "start_time": "2022-05-06T12:25:41.435950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dct = gensim.corpora.Dictionary.load('../input/ase2022/dictionary.gensim')\n",
    "corp = pickle.load(open('../input/ase2022/corpus.pkl', 'rb'))\n",
    "lda = gensim.models.ldamodel.LdaModel.load('../input/ase2022/model.gensim')\n",
    "lda_display = pyLDAvis.gensim.prepare(lda, corp, dct, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 89.478751,
   "end_time": "2022-05-06T12:25:46.399861",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-06T12:24:16.921110",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
